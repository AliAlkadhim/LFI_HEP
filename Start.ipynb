{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cb77096-2352-4a60-b6dc-0534d87ee583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3b70d-895e-4b92-a8f9-0525383c863b",
   "metadata": {},
   "source": [
    "\n",
    "In particle physics, the most important experiment is a counting experiment, represented by a Poisson probability model, where $N$ is the observed count and $\\theta$ is a nuissance parameter, hence the probability model is $P(N|\\theta) = \\text{Poisson}(N,\\theta)$.\n",
    "where the most important parameter is the cross section $\\sigma$, which is related to the mean event count \n",
    "\n",
    "$$\\mu = \\sigma \\mathcal{L} +b$$\n",
    "\n",
    "(more fully it is $\\mu = \\varepsilon \\sigma \\mathcal{L} +b$ where $\\varepsilon = \\prod_i \\varepsilon_i$ is the product of all the efficiencies for the signal). Here the interesting parameter is only the cross section, whereas $\\mathcal{L}, \\ b$ are nuissance parameters. In a Bayesian context, one could eliminate the nuissance parameters by marginalization, i.e. by integrating the probability with respect to the nuissance parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4c213-561e-4581-8e0c-a0208b1881cc",
   "metadata": {},
   "source": [
    "$$ P(N, \\mathcal{L}, b| \\sigma, \\mathcal{L}_{truee}, b_{true}) =L(\\sigma, \\mathcal{L}_{truee}, b_{true})= \\frac{e^{-(\\sigma \\mathcal{L} +b)}(\\sigma \\mathcal{L} +b)^N}{N !} \\ Gamma(\\mathcal{L}_{true}) \\ Gamma(b_{true})$$\n",
    "\n",
    "Therefore we have 3 pieces of data:\n",
    "\n",
    "* Observed count $N$\n",
    "* the estimated luminosity\n",
    "* The estimated background\n",
    "\n",
    "We also have 3 parameters:\n",
    "* The cross section $\\sigma$\n",
    "* The true luminosity $\\mathcal{L}$\n",
    "* The true background $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c799654-f35c-4437-b6ee-025f1a6f2cbf",
   "metadata": {},
   "source": [
    "We want to construct a test to that the probability of making a type I error (rejecting the null hypothesis when it is true) is bounded, it cannot be larger than $\\alpha$. This is done by defining a critical region $R(D)$ where $D$ is the observed data, which is composed of all the values of $\\theta$ that are not rejected by the test $\\delta$\n",
    "\n",
    "$$ R(D) = \\{ \\theta_0 \\in \\Theta \\mid \\text{test } \\delta_{\\theta_o} \\text{ does not reject the null hypothesis} \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30157296-6547-4f09-b5a9-6271be536326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2276c10-143d-4413-b9a1-3074a9ff559a",
   "metadata": {},
   "source": [
    "Trying out the algorithm for a very simple likelihood $L(\\theta) = \\frac{e^{-\\theta} \\theta^N}{N !}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "188e5602-20c8-450b-9b82-c0fefce42c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of $B'$:  10000\n",
      "The observed signal signal $D$ or $N$:  10\n",
      "The observed luminosity:  30\n"
     ]
    }
   ],
   "source": [
    "Bprime=10000\n",
    "D = 10\n",
    "L_obs=30 \n",
    "#b= mean background\n",
    "print('The size of $B\\'$: ', Bprime)\n",
    "print('The observed signal signal $D$ or $N$: ', D)\n",
    "print('The observed luminosity: ', L_obs)\n",
    "# print('The observed background'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8020d4-7f06-4a2b-9283-1cbf24f62c0a",
   "metadata": {},
   "source": [
    "Note that $D$ is only a constant and appeard only in the calculation of the test statistic $\\lambda (D, \\theta_0)$\n",
    "\n",
    "Test statistic could be the likelihood ratio, which is the ratio of the likelihood to the profiled likelihood (likelihood computed at an MLE estimate of one of the parameters), or $t=-2log (this ratio)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b3745-9243-468d-af1f-1fc81c2ec981",
   "metadata": {},
   "source": [
    "### Test statistic $\\lambda$\n",
    "\n",
    "We have several options for this statistic, such as the likelihood ratio, etc. as is shown by Ann Lee's paper. In our case we'd probably like to use the likelihood ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a68fbb0-9452-4683-bed5-1aec416536f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambd(D, theta, thetahat=1):#test statistic\n",
    "    L_num = st.norm.pdf(D, loc= theta, scale=1)#the gaussian pdf of D counts\n",
    "    return L_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd5741-7b5c-4a6a-aef8-df00af5bd552",
   "metadata": {},
   "source": [
    "For our simple example we draw a single $X ~ F_{\\theta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7208fa75-3058-4dbe-8dac-b94f967ec2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T=[[theta_i],[Z_i]]\n",
    "T = [[],[]]\n",
    "for i in range(Bprime):\n",
    "    theta = round(np.random.normal(10))#draw a count theta from a radom poisson prior, it has to be count because its an input to a poisson. This prior should also be close to the cound D\n",
    "    X_mean = np.random.poisson(lam=theta) #draw count samples randomly from a poisson distribution\n",
    "    lam_true = lambd(D, theta)\n",
    "    lam_i = lambd(X_mean, theta)\n",
    "    if lam_i < lam_true:\n",
    "        Z_i=1\n",
    "    else:\n",
    "        Z_i=0\n",
    "    T[0].append(theta)\n",
    "    T[1].append(Z_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a2e1b04-ef21-4606-b585-0f77fc81e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_hat(T):\n",
    "    \"\"\"The expectation value of Z as a relative frequency, this should equal p_hat, the learned parameterized distribution at a given theta\"\"\"\n",
    "    num = np.array(T[1]).sum()\n",
    "    den = Bprime\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf839d13-1674-475f-8150-728159f0e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_hat(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe930c-958a-47e1-a374-d0c00181e809",
   "metadata": {},
   "source": [
    "The actual p-value is $p = \\int P(N|\\theta) d\\theta$ or in our case $p=\\sum_{k=D}^{\\infty} \\text{Poisson}(k|\\theta) = scipy.special.gammainc(D, \\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "965af919-e478-490e-bf34-7108bbcee516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_calculated(theta):\n",
    "    return sp.special.gammainc(D, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fb3ddd4-55e1-4652-baa9-6a95aa4b609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5420702855281478"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = p_calculated(theta = round(np.random.normal(10))); p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e97f2f4-04af-44f4-8ead-67be9b9c5007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7332109015434845"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.gamma(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce52de-413c-4208-8903-5fc6a5e4b1ce",
   "metadata": {},
   "source": [
    "Now that we've built up the dataset, we now need to learn the function $\\hat{p}(D;\\theta)=\\hat{p}(\\theta)$ which is the output of a machine learning regression model, where the training data are $\\vec{\\theta}, \\vec{Z}$ so that the target is $Z$ and the (input) features is $\\theta$, so that the NN model's only parameter is $\\theta$, not $D$ because it's just a fixed constant.\n",
    "## Pytorch Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d6cc3-3580-4d96-8dad-2d4044b11067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3da38-6e59-4062-bf98-9914afb32d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d02531fe-3ba4-4425-a2ac-7c70ed5bb01c",
   "metadata": {},
   "source": [
    "Compare with Directly computing the $p$-value for the Poisson distribution $PoisS(D|\\lambda=\\theta_0)$. So say we use counts $D=0....20$, then we have 20 jobs running in parallel, each working on a different value of $D$. It might be worth generalizing it so that the model is a parameterized function of both $\\theta$ and $D$.\n",
    "\n",
    "For our case, the goal is to generalize step 3, where we have 3 parameters as opposed to 1, $\\theta =\\{\\sigma, \\mathcal{L}, b \\}$ so that we'd have priors for each of these parameters, so at the end, at a fixed $D$, we'd have the output being the p-value being a function of all 3 $\\hat{p}(D; \\sigma, \\mathcal{L}, b)$. Then we can use section 3.4 to construct the confidence interval for the cross section that properly takes into account the two nuissance parameters $\\mathcal{L}, b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ce303-2b53-475b-9baf-0a5b8e665d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5cd4c-9693-4d4d-b4e2-37cc7140066f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
