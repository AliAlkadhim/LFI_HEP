{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770c02da-95fb-4fa6-820c-5fe9255b6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "# force inline plots\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-deep')\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c997ed2c-9ec8-40bc-ad20-3ddecfb2923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of B:  1000000\n",
      "The observed signal signal N (or bold X in the paper):  9\n",
      "The observed luminosity:  30\n"
     ]
    }
   ],
   "source": [
    "%run Generate_Training_Data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebcbd981-548b-420c-a919-4dd7a3be121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.28447325, 0.81173861, 0.36367912, ..., 1.09171563, 2.21233192,\n",
       "        0.94627533]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d3213-3dd6-41fd-883a-1b3282e8f0cf",
   "metadata": {},
   "source": [
    "train_dataset[0]Now that we've built up the dataset, we now need to learn the function $\\hat{p}(D;\\theta)=\\hat{p}(\\theta)$ which is the output of a machine learning regression model, where the training data are $\\vec{\\theta}, \\vec{Z}$ so that the target is $Z$ and the (input) features is $\\theta$, so that the NN model's only parameter is $\\theta$, not $D$ because it's just a fixed constant.\n",
    "## Pytorch Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bcbf42-e0cf-417e-b6b5-5770c23e908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = theta, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e4017a-74c5-4e5d-811f-639085c52e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] [[4.00110329]\n",
      " [1.56452947]\n",
      " [0.04123302]\n",
      " ...\n",
      " [0.34008326]\n",
      " [0.3408608 ]\n",
      " [1.11956975]]\n"
     ]
    }
   ],
   "source": [
    "ntargets = 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(data, \n",
    "                                                                      targets, \n",
    "                                                                      stratify=targets)\n",
    "#Reshape the targets to have shape (something, 1)\n",
    "train_targets = train_targets.reshape(-1,1)\n",
    "test_targets = test_targets.reshape(-1,1)\n",
    "train_data = train_data.reshape(-1,1)\n",
    "test_data = test_data.reshape(-1,1)\n",
    "print(test_targets, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c96806c-511a-41e8-9b55-d7bb1a710399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (250000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(test_data), test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206573fa-0766-4c17-b129-4226f64bf17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.5647098431751753e-16, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()#this is always recommended for logistic regression\n",
    "train_data= sc.fit_transform(train_data)\n",
    "test_data = sc.transform(test_data)\n",
    "train_data.mean(), (train_data.std())**2#check to make sure mean=0, std=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cd2fffe-57a5-4a33-a4d6-392a36999ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([-0.0767]), 'y': tensor([0.])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomDataset:\n",
    "    \"\"\"This takes the index for the data and target and gives dictionary of tensors of data and targets.\n",
    "    For example we could do train_dataset = CustomDataset(train_data, train_targets); test_dataset = CustomDataset(test_data, test_targets)\n",
    " where train and test_dataset are np arrays that are reshaped to (-1,1).\n",
    " Then train_dataset[0] gives a dictionary of samples \"X\" and targets\"\"\"\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets=targets\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        current_sample = self.data[idx, :]\n",
    "        current_target = self.targets[idx]\n",
    "        return {\"x\": torch.tensor(current_sample, dtype = torch.float),\n",
    "               \"y\": torch.tensor(current_target, dtype= torch.float),\n",
    "               }#this already makes the targets made of one tensor (of one value) each\n",
    "    \n",
    "train_dataset = CustomDataset(train_data, train_targets)\n",
    "test_dataset = CustomDataset(test_data, test_targets)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4fd943-888f-4d9d-9a38-bb2b2bee0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=10, \n",
    "                                           num_workers=2, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=10, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03054e9c-84b3-4bd4-aff1-04a9729f3194",
   "metadata": {},
   "source": [
    "Compare with Directly computing the $p$-value for the Poisson distribution $PoisS(D|\\lambda=\\theta_0)$. So say we use counts $D=0....20$, then we have 20 jobs running in parallel, each working on a different value of $D$. It might be worth generalizing it so that the model is a parameterized function of both $\\theta$ and $D$.\n",
    "\n",
    "For our case, the goal is to generalize step 3, where we have 3 parameters as opposed to 1, $\\theta =\\{\\sigma, \\mathcal{L}, b \\}$ so that we'd have priors for each of these parameters, so at the end, at a fixed $D$, we'd have the output being the p-value being a function of all 3 $\\hat{p}(D; \\sigma, \\mathcal{L}, b)$. Then we can use section 3.4 to construct the confidence interval for the cross section that properly takes into account the two nuissance parameters $\\mathcal{L}, b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48dca1f1-d342-4890-929a-c6a7b319caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mymodels import RegressionModel\n",
    "class RegressionModel(nn.Module):\n",
    "    #inherit from the super classdddddddddddd\n",
    "    def __init__(self, nfeatures, ntargets, nlayers, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers):\n",
    "            if len(layers) ==0:\n",
    "                #inital layer has to have size of input features as its input layer\n",
    "                #its output layer can have any size but it must match the size of the input layer of the next linear layer\n",
    "                #here we choose its output layer as the hidden size (fully connected)\n",
    "                layers.append(nn.Linear(nfeatures, hidden_size))\n",
    "                #batch normalization\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                #ReLU activation \n",
    "                layers.append(nn.ReLU())\n",
    "            else:\n",
    "                #if this is not the first layer (we dont have layers)\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                layers.append(nn.ReLU())\n",
    "                #output layer:\n",
    "        layers.append(nn.Linear(hidden_size, ntargets)) \n",
    "        \n",
    "        layers.append(nn.Sigmoid())\n",
    "            #we have defined sequential model using the layers in oulist \n",
    "        self.model = nn.Sequential(*layers)\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b2c781f-2909-4b30-8d57-b42a9d55ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.3, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout(p=0.3, inplace=False)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Dropout(p=0.3, inplace=False)\n",
      "    (19): ReLU()\n",
      "    (20): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (21): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model =  RegressionModel(nfeatures=train_data.shape[1], \n",
    "               ntargets=1,\n",
    "               nlayers=5, \n",
    "               hidden_size=128, \n",
    "               dropout=0.3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f88e06-9deb-41cf-8b6d-c59b85df8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionEngine:\n",
    "    \"\"\"loss, training and evaluation\"\"\"\n",
    "    def __init__(self, model, optimizer):\n",
    "                 #, device):\n",
    "        self.model = model\n",
    "        #self.device= device\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    #the loss function returns the loss function. It is a static method so it doesn't need self\n",
    "    @staticmethod\n",
    "    def loss_fun(targets, outputs):\n",
    "         return nn.MSELoss()(outputs, targets)\n",
    "\n",
    "\n",
    "    def train(self, data_loader):\n",
    "        \"\"\"the training function: takes the training dataloader\"\"\"\n",
    "        self.model.train()\n",
    "        final_loss = 0\n",
    "        for data in data_loader:\n",
    "            self.optimizer.zero_grad()#only optimize weights for the current batch, otherwise it's meaningless!\n",
    "            inputs = data[\"x\"]\n",
    "            targets = data[\"y\"]\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.loss_fun(targets, outputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            final_loss += loss.item()\n",
    "            return final_loss / len(data_loader)\n",
    "\n",
    "    \n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\"the training function: takes the training dataloader\"\"\"\n",
    "        self.model.eval()\n",
    "        final_loss = 0\n",
    "        for data in data_loader:\n",
    "            inputs = data[\"x\"]#.to(self.device)\n",
    "            targets = data[\"y\"]#.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.loss_fun(targets, outputs)\n",
    "            final_loss += loss.item()\n",
    "            return outputs\n",
    "            #return final_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6771a55f-a87b-40a1-b06e-850000362598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, engine, early_stopping_iter, epochs):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "    eng = RegressionEngine(model=model, optimizer = optimizer)\n",
    "    best_loss = np.inf\n",
    "    early_stopping_iter = 10\n",
    "    early_stopping_counter = 0\n",
    "    EPOCHS=22\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = eng.train(train_loader)\n",
    "        test_loss = eng.train(test_loader)\n",
    "        print(\"Epoch : %-10g, Training Loss: %-10g, Test Loss: %-10g\" % (epoch, train_loss, test_loss))\n",
    "        #print(f\"{epoch}, {train_loss}, {test_loss}\")\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter > early_stopping_iter:\n",
    "            #if we are not improving for 10 iterations then break the loop\n",
    "            #we could save best model here\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa4a5996-36b7-45d8-83b7-8e84894671b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0         , Training Loss: 3.98226e-07, Test Loss: 8.61863e-07\n",
      "Epoch : 1         , Training Loss: 3.64439e-07, Test Loss: 7.7058e-07\n",
      "Epoch : 2         , Training Loss: 3.61309e-07, Test Loss: 7.70726e-07\n",
      "Epoch : 3         , Training Loss: 2.86147e-07, Test Loss: 7.24303e-07\n",
      "Epoch : 4         , Training Loss: 1.74792e-07, Test Loss: 6.36877e-07\n",
      "Epoch : 5         , Training Loss: 1.86181e-07, Test Loss: 4.17103e-07\n",
      "Epoch : 6         , Training Loss: 1.59721e-07, Test Loss: 4.32235e-07\n",
      "Epoch : 7         , Training Loss: 1.2331e-07, Test Loss: 3.45689e-07\n",
      "Epoch : 8         , Training Loss: 1.47526e-07, Test Loss: 3.89183e-07\n",
      "Epoch : 9         , Training Loss: 7.61074e-08, Test Loss: 3.42965e-07\n",
      "Epoch : 10        , Training Loss: 1.31316e-07, Test Loss: 2.28732e-07\n",
      "Epoch : 11        , Training Loss: 1.42312e-07, Test Loss: 1.6924e-07\n",
      "Epoch : 12        , Training Loss: 6.74564e-08, Test Loss: 1.09543e-07\n",
      "Epoch : 13        , Training Loss: 9.77996e-08, Test Loss: 1.45653e-07\n",
      "Epoch : 14        , Training Loss: 4.50776e-08, Test Loss: 1.8281e-07\n",
      "Epoch : 15        , Training Loss: 5.18109e-08, Test Loss: 1.09472e-07\n",
      "Epoch : 16        , Training Loss: 3.61386e-08, Test Loss: 1.07594e-07\n",
      "Epoch : 17        , Training Loss: 4.75988e-08, Test Loss: 1.23768e-07\n",
      "Epoch : 18        , Training Loss: 2.70883e-08, Test Loss: 6.45459e-08\n",
      "Epoch : 19        , Training Loss: 4.3335e-08, Test Loss: 8.50858e-08\n",
      "Epoch : 20        , Training Loss: 1.48782e-08, Test Loss: 6.69944e-08\n",
      "Epoch : 21        , Training Loss: 2.12112e-08, Test Loss: 1.02531e-07\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train(optimizer, engine =RegressionEngine(model=model, optimizer = optimizer),\n",
    "      early_stopping_iter = 10,\n",
    "      epochs=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ffe2d65-6034-46e7-a477-86ac3d6ec3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6afabaef-dc55-4af6-802f-94e3fe681ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    accuracies = []\n",
    "\n",
    "    #evaluate\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data_cp = copy.deepcopy(data)\n",
    "\n",
    "            xtest = data_cp[\"x\"]\n",
    "            ytest = data_cp[\"y\"]\n",
    "            output = model(xtest)\n",
    "            labels.append(ytest)\n",
    "            outputs.append(output)\n",
    "\n",
    "            y_predicted_cls = output.round()\n",
    "            acc = y_predicted_cls.eq(ytest).sum() / float(ytest.shape[0])#bumber of correct predictions/sizeofytest\n",
    "            #accuracies.append(acc.numpy())\n",
    "            #print(f'accuracy: {acc.item():.4f}')\n",
    "\n",
    "            del data_cp\n",
    "\n",
    "    #     acc = y_predicted_cls.eq(ytest).sum() / float(ytest.shape[0])\n",
    "    #     print(f'accuracy: {acc.item():.4f}')\n",
    "            \n",
    "    OUTPUTS = torch.cat(outputs).view(-1).numpy()\n",
    "\n",
    "    LABELS = torch.cat(labels).view(-1).numpy()\n",
    "    print('outputs of model: ', OUTPUTS)\n",
    "    print('\\nactual labels (targets Z): ', LABELS)\n",
    "    return OUTPUTS, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f697f904-f7d2-4163-981a-547a7147ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs of model:  [0.06671236 0.13141686 0.13383634 ... 0.1803793  0.11944921 0.23281641]\n",
      "\n",
      "actual labels (targets Z):  [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "OUTPUTS, LABELS = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "339bf3e6-a4a3-4f44-939f-e784065dbe5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000,), (250000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUTS.shape , LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f39b31-3e62-49be-a0c5-579e9e8f0deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.hist(OUTPUTS, bins=50, density=True, label = \"Outputs $\\hat{y}$\")\n",
    "plt.hist(LABELS, bins=50,density=True, label = \"Labels $y$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9481a2a8-baaf-4c8f-bd87-a5f489c38bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob_1(model, X):\n",
    "    X = torch.from_numpy(X).float()\n",
    "    model.eval()\n",
    "    P_y_equals_1 = model(X)\n",
    "    P_y_equals_1 = P_y_equals_1.squeeze()\n",
    "    return P_y_equals_1.detach().numpy().flatten()#detaches it from the computational history/prevent future computations from being tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff8e957d-425a-4988-b234-d7f8a29f1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_Z_equals_1 = calc_prob_1(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ed7a683-9779-4eb4-bf2b-6ed849cedd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc6cf1f9750>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(P_Z_equals_1, label='$\\hat{p}(Z=1|x)$')\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db13245-6fa9-4b6c-86da-ad44ced6c125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f947ca8e710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAENCAYAAADjW7WQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUgElEQVR4nO3df7Bc5X3f8ffHCCwaDOaHoKBLIjkmYNDUYAQljs1QgwOhptAZU4s2BoI8Ghvikro/DP6jHqdDSxsmP4gLLuM4wKSAqUPNjzE4WAk22IAiXGxAhKJGKVwgIBTHxmmgRv72jz0yW3Glu1d3dy/3Pu/XzM7uefY5Z7/PSPPR0bNnn5OqQpLUhjfNdQGSpPEx9CWpIYa+JDXE0Jekhhj6ktSQRXNdwHQOOOCAWrZs2VyXIUnzykMPPfRiVS3Zvv0NH/rLli1j/fr1c12GJM0rSf73VO1O70hSQwx9SWqIoS9JDXnDz+lL0kz96Ec/YnJykpdffnmuSxm5xYsXMzExwe677z5Qf0Nf0oIzOTnJW97yFpYtW0aSuS5nZKqKLVu2MDk5yfLlywfax+kdSQvOyy+/zP7777+gAx8gCfvvv/+M/kdj6EtakBZ64G8z03Ea+pLUEENfkhpi6O/M7bfPdQWSNFRevSNpwbv9ieGewJ1x+BkD9ZucnOSb3/wmH/rQh3bpcy644ALuuOMODjzwQB599NFdOsb2PNOXpBFZu3Yt3/72t3d5//PPP5+77rpriBUZ+pI0Evfddx+f+MQn+NKXvsTRRx/Npk2bZnyME088kf3222+odTm9I0kj8J73vIfjjjuOK664ghUrVvyk/b3vfS8vvfTS6/pfccUVnHLKKSOvy9CXpBF54oknOPzww/+/tnvvvXeOqukx9CVpBLZs2cI+++zzujVxPNOXpAVo06ZNHHLIIa9r90xfkkZs0Essh+mII47gxRdfZMWKFVxzzTW8+93vnvExzjnnHO655x5efPFFJiYm+MxnPsPq1atnVZehL0kjsNdee7Fu3bpZHePGG28cUjWv8ZJNSWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkP8cZakhW/Yd8E7Yzw3Ubnrrru4+OKL2bp1Kx/5yEe45JJLduk4/TzTl6QRmc1NVLZu3cpFF13EnXfeyYYNG7jxxhvZsGHDrGsy9CVpBGZ7E5V169bx9re/nbe97W3ssccerFq1iltvvXXWdTm9I0kjMNubqDzzzDMceuihP9memJjgwQcfnHVdhr4kjchsbqJSVa9rSzLrmgx9SRqB2d5EZWJigqeffvon25OTk1Ouzz9Thr4kjcBsb6Jy3HHH8eSTT7Jp0yaWLl3KTTfdxA033DDrugYO/SS7AeuBZ6rqA0n2A74ILAP+AvgnVfW9ru+lwGpgK/DPq+qrXfuxwLXAnsBXgItrqv/DSNIwDXiJ5TDN9iYqixYt4rOf/SynnnoqW7du5YILLuCoo46adV0zOdO/GHgc2LvbvgRYW1WXJ7mk2/5kkiOBVcBRwCHA15L8XFVtBa4G1gAP0Av904A7Zz0KSXqDGcZNVE4//XROP/30IVXUM9Alm0kmgH8IfL6v+Uzguu71dcBZfe03VdUrVbUJ2Agcn+RgYO+qur87u7++bx9J0hgMep3+bwP/BvhxX9tBVfUcQPd8YNe+FHi6r99k17a0e719++skWZNkfZL1mzdvHrBESdJ0pg39JB8AXqiqhwY85lTXFNVO2l/fWHVNVa2sqpVLliwZ8GMl6TWtfF0403EOMqf/C8A/SnI6sBjYO8kfAM8nObiqnuumbl7o+k8Ch/btPwE827VPTNEuSUO1ePFitmzZwv777z+Ua9vfqKqKLVu2sHjx4oH3mTb0q+pS4FKAJCcB/6qqfjnJbwDnAZd3z9t+H3wbcEOS36T3Re5hwLqq2prkpSQnAA8C5wK/O3ClkjSgiYkJJicnaWF6ePHixUxMTEzfsTOb6/QvB25Oshp4CjgboKoeS3IzsAF4Fbiou3IH4GO8dsnmnXjljqQR2H333Vm+fPlcl/GGNKPQr6p7gHu611uAk3fQ7zLgsina1wMrXr+HJGkcXGVTkhpi6EtSQwx9SWqIoS9JDTH0Jakhhv50hn1DZUmaQ4a+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jasi0oZ9kcZJ1Sb6T5LEkn+na90tyd5Inu+d9+/a5NMnGJE8kObWv/dgkj3TvXZkkoxmWJGkqg5zpvwK8r6reCRwNnJbkBOASYG1VHQas7bZJciSwCjgKOA24Kslu3bGuBtYAh3WP04Y3FEnSdKYN/er5Ybe5e/co4Ezguq79OuCs7vWZwE1V9UpVbQI2AscnORjYu6rur6oCru/bR5I0BgPN6SfZLcnDwAvA3VX1IHBQVT0H0D0f2HVfCjzdt/tk17a0e719+1SftybJ+iTrN2/ePIPhSJJ2ZqDQr6qtVXU0MEHvrH3FTrpPNU9fO2mf6vOuqaqVVbVyyZIlg5QoSRrAjK7eqaq/Bu6hNxf/fDdlQ/f8QtdtEji0b7cJ4NmufWKKdknSmAxy9c6SJG/tXu8JnAL8GXAbcF7X7Tzg1u71bcCqJG9OspzeF7bruimgl5Kc0F21c27fPpKkMVg0QJ+Dgeu6K3DeBNxcVXckuR+4Oclq4CngbICqeizJzcAG4FXgoqra2h3rY8C1wJ7And1DkjQm04Z+VX0XOGaK9i3AyTvY5zLgsina1wM7+z5AkjRC/iJ3Jm6/fa4rkKRZMfQlqSGG/o54Vi9pATL0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwz9qdx++1xXIEkjYehLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6g/ASTkkLhKEvSQ0x9CWpIdOGfpJDk/xJkseTPJbk4q59vyR3J3mye963b59Lk2xM8kSSU/vaj03ySPfelUkymmFJkqYyyJn+q8C/rKp3ACcAFyU5ErgEWFtVhwFru22691YBRwGnAVcl2a071tXAGuCw7nHaEMciSZrGtKFfVc9V1be71y8BjwNLgTOB67pu1wFnda/PBG6qqleqahOwETg+ycHA3lV1f1UVcH3fPpKkMZjRnH6SZcAxwIPAQVX1HPT+YQAO7LotBZ7u222ya1vavd6+fX7wCh5JC8DAoZ9kL+APgV+rqh/srOsUbbWT9qk+a02S9UnWb968edASJUnTGCj0k+xOL/D/a1Xd0jU/303Z0D2/0LVPAof27T4BPNu1T0zR/jpVdU1VrayqlUuWLBl0LJKkaQxy9U6A3wMer6rf7HvrNuC87vV5wK197auSvDnJcnpf2K7rpoBeSnJCd8xz+/aRJI3BogH6/ALwYeCRJA93bZ8CLgduTrIaeAo4G6CqHktyM7CB3pU/F1XV1m6/jwHXAnsCd3YPSdKYTBv6VXUfU8/HA5y8g30uAy6bon09sGImBUqShsdf5EpSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIdOGfpIvJHkhyaN9bfsluTvJk93zvn3vXZpkY5Inkpza135skke6965MkuEPR5K0M4Oc6V8LnLZd2yXA2qo6DFjbbZPkSGAVcFS3z1VJduv2uRpYAxzWPbY/piRpxKYN/ar6BvBX2zWfCVzXvb4OOKuv/aaqeqWqNgEbgeOTHAzsXVX3V1UB1/ftI0kak12d0z+oqp4D6J4P7NqXAk/39Zvs2pZ2r7dvn1KSNUnWJ1m/efPmXSxRkrS9YX+RO9U8fe2kfUpVdU1VrayqlUuWLBlacZLUul0N/ee7KRu65xe69kng0L5+E8CzXfvEFO2SpDHa1dC/DTive30ecGtf+6okb06ynN4Xtuu6KaCXkpzQXbVzbt8+byy33z7XFUjSyCyarkOSG4GTgAOSTAKfBi4Hbk6yGngKOBugqh5LcjOwAXgVuKiqtnaH+hi9K4H2BO7sHpKkMZo29KvqnB28dfIO+l8GXDZF+3pgxYyqkyQNlb/IlaSGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEEP/jcobtEsaAUNfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0N8Vo1722GWVJY2IoT9T2wJ5VMFs4EsaoUVzXYA6hr2kMRh76Cc5DfgdYDfg81V1+bhrGJrpgvqMM3p9zjhjZvtJ0oiMNfST7Ab8Z+D9wCTwp0luq6oN46xjbEY9FSRJMzTuOf3jgY1V9edV9X+Bm4Azx1yDJDVr3NM7S4Gn+7Yngb+/facka4A13eYPkzyxi593APDiLu47XznmNrQ25tbGC7Mf889M1Tju0M8UbfW6hqprgGtm/WHJ+qpaOdvjzCeOuQ2tjbm18cLoxjzu6Z1J4NC+7Qng2THXIEnNGnfo/ylwWJLlSfYAVgG3jbkGSWrWWKd3qurVJL8KfJXeJZtfqKrHRviRs54imocccxtaG3Nr44URjTlVr5tSlyQtUC7DIEkNMfQlqSELIvSTnJbkiSQbk1wyxftJcmX3/neTvGsu6hyWAcb7z7pxfjfJt5K8cy7qHKbpxtzX77gkW5N8cJz1jcIgY05yUpKHkzyW5OvjrnHYBvi7vU+S25N8pxvzr8xFncOS5AtJXkjy6A7eH352VdW8ftD7Qvh/AW8D9gC+Axy5XZ/TgTvp/U7gBODBua57xON9N7Bv9/qX5vN4Bx1zX78/Br4CfHCu6x7Dn/NbgQ3AT3fbB8513WMY86eA/9i9XgL8FbDHXNc+izGfCLwLeHQH7w89uxbCmf4gSzucCVxfPQ8Ab01y8LgLHZJpx1tV36qq73WbD9D7PcR8NujyHR8H/hB4YZzFjcggY/6nwC1V9RRAVc33cQ8y5gLekiTAXvRC/9Xxljk8VfUNemPYkaFn10II/amWdli6C33mi5mOZTW9M4X5bNoxJ1kK/GPgc2Osa5QG+XP+OWDfJPckeSjJuWOrbjQGGfNngXfQ+1HnI8DFVfXj8ZQ3J4aeXQthPf1BlnYYaPmHeWLgsST5B/RC/z0jrWj0BhnzbwOfrKqtvZPAeW+QMS8CjgVOBvYE7k/yQFX9z1EXNyKDjPlU4GHgfcDPAncnubeqfjDi2ubK0LNrIYT+IEs7LKTlHwYaS5K/B3we+KWq2jKm2kZlkDGvBG7qAv8A4PQkr1bVl8dS4fAN+vf6xar6G+BvknwDeCcwX0N/kDH/CnB59Sa8NybZBBwBrBtPiWM39OxaCNM7gyztcBtwbvdN+AnA96vquXEXOiTTjjfJTwO3AB+ex2d9/aYdc1Utr6plVbUM+BJw4TwOfBjs7/WtwHuTLEryd+itWPv4mOscpkHG/BS9/9mQ5CDgcODPx1rleA09u+b9mX7tYGmHJB/t3v8cvas5Tgc2Av+H3tnCvDTgeP8tsD9wVXfm+2rN4xUKBxzzgjLImKvq8SR3Ad8FfkzvTnRTXvo3Hwz45/zvgGuTPEJv6uOTVTVvl1xOciNwEnBAkkng08DuMLrschkGSWrIQpjekSQNyNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH01YQkpya5d67r2CbJ+UnumUH/LyZZPcKS1AhDXwtetwzvb9H7teO4PnNVknuT/CDJMJb+/TTw75PsOYRjqWGGvlrwi/RuyvEnY/zM7wFXAb82jINV1Z/R+yn+OcM4ntpl6GveS/LzSb6f5D8keTLJS0luSfJTXZezgK91KzOS5E1d/1/c7jj/PckVw6ipqr5aVTcy4GJgST6e5C+SvLnbfkeSv0xydl+3u7uxSLvM0NdCcAywN70FuFYCR9FbZ/7C7v130butIADdTTcepLcqJQBJTgF+Hvj1/gMnuSrJX+/kscP79c7Q1cDLwIVJlgN/BFxaVf+tr88j3VikXTbvV9mU6IX+16tqWwB/P8lXgCO77X2B7W+ycT+92/ORZBG9m7B8avubcVTVhbz2j8fIdCtM/mvg94FfBX6jqn5/u24/APYbdS1a2DzT10JwDPAH27UdzGv3yv0evf8J9PsWr53pXwj8Lb3AnUuPAj9F7z6xV07x/t7s/H6q0rQMfc1rSXYHVgDP9LUdBLwf+HLX9D947ax/mwforWG+kt6VMR+vKdYZT/K5JD/cyeNTQxrHIcDXgP8CnJjkiCm6rejGIu0yp3c03x1J74Ybv5zkj4G/C1wL3FJV93d9vgz8bv9OVfX9JBuALwJ3VNUDUx28qj4KfHSmRSXZjd7NMPbothd3b72y/T8uSZbQC/zrqurXk+wFXAF8YLvDvp+5/9+I5jnP9DXfHQN8HfhL4HngPuCb9G4Iv81XgVeTnLTdvvcDS4BhfRnb78P0poy23QXqb7vHz/R3SrJP1+crVbXtS+RPA+/rvlze1u9w4DDghhHUqoZ45yzNa0l+B/hxVf2LafqdRu+L2hP72r4G/FFV/acRlzlVPecD51fVSQP2vxFYW1WfH2VdWvic3tF8dwy96Zydqqq7gLu2bSdZQ28q6LdGVtkQVZU/ytJQGPqat7rlFd5J76qXQfc5nt6PnDYBH6yqH42ovOk8zAD/WEnD5vSOJDXEL3IlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrI/wMPcPA7mwgfRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p[p>0.5], bins=50, color='g',\n",
    "            histtype='stepfilled',\n",
    "            alpha=0.3,label = '$t = 1$')\n",
    "\n",
    "plt.hist(p[p<0.5], bins=50, color='r',\n",
    "            histtype='stepfilled',\n",
    "            alpha=0.3,label = '$t = 0$')\n",
    "plt.xlabel('$p(y=1|x)$', fontsize=13)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cbfbe1-a1ee-4762-9c40-b0b5c6329b03",
   "metadata": {},
   "source": [
    "st.expon.rvs(size=len(test_data))The actual p-value is $p = \\int P(N|\\theta) d\\theta$ or in our case $p=\\sum_{k=D+1}^{\\infty} \\text{Poisson}(k|\\theta) = scipy.special.gammainc(D, \\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f67dd34e-74df-4c70-8feb-da09fae8dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "D=9\n",
    "def p_calculated(theta):\n",
    "    p_computed = sp.special.gammainc(D, theta)\n",
    "    p_computed = np.array(p_computed)\n",
    "    return p_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "167697f5-8745-411a-ac8f-f1c780c2fec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_calc = p_calculated(10); type(p_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8341aec7-71ac-4686-bfb4-3564d62f146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(st.expon.rvs(size=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5334770b-feec-4665-accf-67e0fed6a1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, numpy.ndarray)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data), type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22eb985b-1b10-4c21-b344-72336c914a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "th = st.expon.rvs(size=len(test_data)) \n",
    "#th = torch.from_numpy(th)\n",
    "print(th.shape, type(th))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb20ea-b999-40db-bfe3-55ec7e151ac0",
   "metadata": {},
   "source": [
    "I might need to write a validation script with no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335ea12-dde2-41e0-8726-ea18c53384b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, theta):\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48be4d8a-483f-424f-abe6-4583999f5a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x250000 and 1x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16030/4163299590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_prob_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mp_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16030/2557079563.py\u001b[0m in \u001b[0;36mcalc_prob_1\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mP_y_equals_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mP_y_equals_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP_y_equals_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mP_y_equals_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16030/195676802.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x250000 and 1x128)"
     ]
    }
   ],
   "source": [
    "p_hat = calc_prob_1(model, th); p_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e1b4da8-59b9-4a1c-af8c-ac4fd0dddcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_p_values(model):\n",
    "    theta = st.expon.rvs(size=len(test_data))\n",
    "    \n",
    "    p_hat = compute_prob(model, theta)#model evaluated at theta\n",
    "    p_calculated = [p_calculated(theta = theta[i]) for i in range(len(theta))]\n",
    "    \n",
    "    plt.hist(p_hat, label = r'$\\hat{p}$', alpha=0.3)\n",
    "    plt.hist(p_calculated, label='$p$ calculated', alpha=0.3)\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7037e065-f805-41c5-b14f-808cd701ea4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x25000 and 1x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12983/3597554309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_p_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_12983/2637657473.py\u001b[0m in \u001b[0;36mcompare_p_values\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mp_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#model evaluated at theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mp_calculated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp_calculated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12983/3437482318.py\u001b[0m in \u001b[0;36mcompute_prob\u001b[0;34m(model, xx)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# compute p(1|x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# squeeze() removes extraneous dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12983/195676802.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x25000 and 1x128)"
     ]
    }
   ],
   "source": [
    "compare_p_values(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feca878-2070-4522-b88c-ddbb329d37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Algorithm2(D=2, theta_0):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return actual_p_value, regressed_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ca910987-45ca-4197-9d17-707287948334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_hat(T):\n",
    "    \"\"\"The expectation value of Z as a relative frequency, this should equal p_hat, the learned parameterized distribution at a given theta\"\"\"\n",
    "    num = np.array(T[1]).sum()\n",
    "    den = Bprime\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01507c62-bd5c-4889-b05d-015768d8a4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
